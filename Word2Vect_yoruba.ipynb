{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Word2Vec and FastText Word Embedding with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '../data/yorubaDS2020/'\n",
    "df = pd.read_table(source_dir + 'yoruba_on_tweets.txt', names=['text'], encoding='utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text, remove_polish_letters):\n",
    "    ''' Pre process and convert texts to a list of words \n",
    "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
    "    # Remove all numbers from text\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = sub(\"[0123456789]\", \"\", text)\n",
    "    text = sub(\" +\", \" \", text)\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: text_to_word_list(x, unidecode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>búrẹ́dì rèé bí àmàlà yìí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>káááábíbèsí o. mo yí'kàá ọ̀tún mo yí'kàá òsì o.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text\n",
       "0                         búrẹ́dì rèé bí àmàlà yìí\n",
       "1  káááábíbèsí o. mo yí'kàá ọ̀tún mo yí'kàá òsì o."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoruba_model = df.copy()\n",
    "yoruba_model = yoruba_model[yoruba_model.text.str.len()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:06:47: collecting all words and their counts\n",
      "INFO - 14:06:47: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 14:06:50: collected 3277 word types from a corpus of 1254223 words (unigram + bigrams) and 13913 sentences\n",
      "INFO - 14:06:50: using 3277 counts as vocab in Phrases<0 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 14:06:50: source_vocab length 3277\n",
      "INFO - 14:06:50: Phraser built with 5 5 phrasegrams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['búrẹ́dì rèé bí àmàlà yìí',\n",
       " \"káááábíbèsí o. mo yí'kàá ọ̀tún mo yí'kàá òsì o.\",\n",
       " 'bó ti wà ní lìkì ní nbẹ ní gbànja. ní tèmi o, adìẹ funfun ọ̀hún ò bá dùn ún dín jẹ o jàre.',\n",
       " 'a ti gba òmìnira ọjọ́ ti pẹ́, ó wá ku ìdándè.',\n",
       " \"ìbànújẹ́ ò sí fún ẹni t'éyín rẹ̀ ta'áta. ẹ̀rín ni ní gbogboògbà.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in yoruba_model.text]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:06:50: collecting all words and their counts\n",
      "WARNING - 14:06:50: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "INFO - 14:06:50: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:06:50: collected 141 word types from a corpus of 1254223 raw words and 13913 sentences\n",
      "INFO - 14:06:50: Loading a fresh vocabulary\n",
      "INFO - 14:06:50: min_count=3 retains 102 unique words (72% of original 141, drops 39)\n",
      "INFO - 14:06:50: min_count=3 leaves 1254174 word corpus (99% of original 1254223, drops 49)\n",
      "INFO - 14:06:50: deleting the raw counts dictionary of 141 items\n",
      "INFO - 14:06:50: sample=1e-05 downsamples 76 most-common words\n",
      "INFO - 14:06:50: downsampling leaves estimated 27995 word corpus (2.2% of prior 1254174)\n",
      "INFO - 14:06:50: estimated required memory for 102 words and 300 dimensions: 295800 bytes\n",
      "INFO - 14:06:50: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "model_word2vec = Word2Vec(min_count=3,window=4,size=300,sample=1e-5, \n",
    "                          alpha=0.03, min_alpha=0.0007, negative=20,\n",
    "                          sg=0, workers=multiprocessing.cpu_count()-1)\n",
    "# size: The number of dimensions of the embeddings and the default is 100.\n",
    "# window: The maximum distance between a target word and words around the target word. The default window is 5.\n",
    "# min_count: The minimum count of words to consider when training the model; \n",
    "#            words with occurrence less than this count will be ignored. The default for min_count is 5.\n",
    "# sg: it is used to indicate skip-gram or CBOW but when CBOW=0 or skip gram=1\n",
    "start = time()\n",
    "model_word2vec.build_vocab(sentences, progress_per=50000)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:06:50: training model with 7 workers on 102 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:50: EPOCH - 1 : training on 1254223 raw words (28110 effective words) took 0.4s, 78414 effective words/s\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:51: EPOCH - 2 : training on 1254223 raw words (28199 effective words) took 0.3s, 82193 effective words/s\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:51: EPOCH - 3 : training on 1254223 raw words (28139 effective words) took 0.4s, 69913 effective words/s\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:52: EPOCH - 4 : training on 1254223 raw words (28045 effective words) took 0.5s, 61260 effective words/s\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:52: EPOCH - 5 : training on 1254223 raw words (27821 effective words) took 0.4s, 67144 effective words/s\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:53: EPOCH - 6 : training on 1254223 raw words (27729 effective words) took 0.4s, 62427 effective words/s\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:53: EPOCH - 7 : training on 1254223 raw words (28031 effective words) took 0.4s, 67464 effective words/s\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:53: EPOCH - 8 : training on 1254223 raw words (27913 effective words) took 0.4s, 73304 effective words/s\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:54: EPOCH - 9 : training on 1254223 raw words (27962 effective words) took 0.4s, 79388 effective words/s\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:54: EPOCH - 10 : training on 1254223 raw words (28315 effective words) took 0.4s, 72265 effective words/s\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:55: EPOCH - 11 : training on 1254223 raw words (27811 effective words) took 0.3s, 86306 effective words/s\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:55: EPOCH - 12 : training on 1254223 raw words (28067 effective words) took 0.4s, 65430 effective words/s\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:55: EPOCH - 13 : training on 1254223 raw words (27959 effective words) took 0.4s, 63949 effective words/s\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:56: EPOCH - 14 : training on 1254223 raw words (28078 effective words) took 0.4s, 70822 effective words/s\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:56: EPOCH - 15 : training on 1254223 raw words (28142 effective words) took 0.5s, 59644 effective words/s\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:57: EPOCH - 16 : training on 1254223 raw words (27844 effective words) took 0.4s, 71289 effective words/s\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:57: EPOCH - 17 : training on 1254223 raw words (27896 effective words) took 0.4s, 66789 effective words/s\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:58: EPOCH - 18 : training on 1254223 raw words (28109 effective words) took 0.4s, 69772 effective words/s\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:58: EPOCH - 19 : training on 1254223 raw words (27920 effective words) took 0.4s, 75509 effective words/s\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:58: EPOCH - 20 : training on 1254223 raw words (27691 effective words) took 0.3s, 87038 effective words/s\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:59: EPOCH - 21 : training on 1254223 raw words (27788 effective words) took 0.3s, 86860 effective words/s\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:59: EPOCH - 22 : training on 1254223 raw words (28152 effective words) took 0.3s, 81495 effective words/s\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:59: EPOCH - 23 : training on 1254223 raw words (27984 effective words) took 0.4s, 75142 effective words/s\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:00: EPOCH - 24 : training on 1254223 raw words (27959 effective words) took 0.4s, 70131 effective words/s\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:00: EPOCH - 25 : training on 1254223 raw words (28077 effective words) took 0.4s, 71797 effective words/s\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:00: EPOCH - 26 : training on 1254223 raw words (27952 effective words) took 0.3s, 84045 effective words/s\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:01: EPOCH - 27 : training on 1254223 raw words (28219 effective words) took 0.4s, 79971 effective words/s\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:01: EPOCH - 28 : training on 1254223 raw words (27970 effective words) took 0.3s, 81385 effective words/s\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:02: EPOCH - 29 : training on 1254223 raw words (28138 effective words) took 0.4s, 70925 effective words/s\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:02: EPOCH - 30 : training on 1254223 raw words (28240 effective words) took 0.4s, 72534 effective words/s\n",
      "INFO - 14:07:02: training on a 37626690 raw words (840260 effective words) took 11.9s, 70695 effective words/s\n",
      "INFO - 14:07:02: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.2 mins\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model_word2vec.train(sentences, total_examples=model_word2vec.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "model_word2vec.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:07:02: saving Word2Vec object under yoruba_word2vec.model, separately None\n",
      "INFO - 14:07:02: not storing attribute vectors_norm\n",
      "INFO - 14:07:02: not storing attribute cum_table\n",
      "/home/dupsy/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "INFO - 14:07:02: saved yoruba_word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model_word2vec.save(\"yoruba_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export = yoruba_model.copy()\n",
    "file_export['old_title'] = file_export.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export.old_title = file_export.old_title.str.join('')\n",
    "file_export.text = file_export.text.apply(lambda x: ''.join(bigram[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export[['text']].to_csv('cleaned_yoruba_on_tweet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word, size):\n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    \n",
    "    close_words = model.similar_by_word(word)\n",
    "\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "\n",
    "        tsne = TSNE(n_components=2, random_state=0)\n",
    "        np.set_printoptions(suppress=True)\n",
    "        Y = tsne.fit_transform(arr)\n",
    "\n",
    "        x_coords = Y[:, 0]\n",
    "        y_coords = Y[:, 1]\n",
    "        plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "        plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "        plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_closestwords_tsnescatterplot(model_word2vec, 'gba', 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model_fastText = FastText(sentences, size=100, window=5, min_count=5, workers=4,sg=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
